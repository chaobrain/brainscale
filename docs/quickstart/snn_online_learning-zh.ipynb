{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 脉冲神经网络的在线学习\n",
    "\n",
    "\n",
    "在[关键概念](./concepts-zh.ipynb)一章中，我们介绍了`brainscale`在线学习的基础知识。在本节中，我们将讨论如何基于``brainscale``进行脉冲神经网络（Spiking Neural Networks，SNNs）的在线学习。\n",
    "\n",
    "脉冲神经网络（Spiking Neural Networks, SNNs）是生物神经系统的一种更真实的建模方式，其核心在于使用离散的脉冲信号传递信息。与传统的神经网络不同，SNNs通过脉冲时间编码（Temporal Coding）来捕捉信息，强调了脉冲发放的时序和频率。在在线学习中，SNNs能够通过对脉冲事件的实时处理，适应动态环境，实现持续学习。这种学习方式不仅提高了计算效率，还使得网络在时间和空间上具备更强的适应能力，能有效处理时间序列数据。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "59500c56c6226022"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import brainstate as bst\n",
    "import brainunit as u\n",
    "\n",
    "import brainscale\n",
    "\n",
    "import jax"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fb33cf435d65c4e6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. SNNs的基本概念\n",
    "\n",
    "一般来说,一个脉冲神经网络分包含至少三个部分:一个部分是神经元的动力学,第二部分是突触的动力学，第三部分是神经元之间通过突触连接形成的动力学的交互。在这里，我们将基于简单的样例来介绍这三个部分的基本概念。\n",
    "\n",
    "**LIF神经元模型**\n",
    "\n",
    "最常见的神经元模型是 Leaky Integrate-and-fire (LIF) 神经元模型，其动力学方程如下：\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\tau_m \\frac{dV}{dt} =& -V + V_\\mathrm{rest} + R I, \\\\\n",
    "Z =& \\Theta(V - V_{\\mathrm{th}}), \\\\\n",
    "V =& V_{\\mathrm{reset}} \\quad \\text{if} \\quad Z = 1\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "其中，$V$ 是神经元的膜电位，$\\tau_m$ 是膜电位的时间常数，$V_{\\mathrm{rest}}$ 是静息电位，$R$ 是膜电阻，$I$ 是输入电流，$V_{\\mathrm{th}}$ 是阈值电位，$\\Theta$ 是阶跃函数，$Z$ 是输出脉冲，$V_{\\mathrm{reset}}$ 是重置电位。\n",
    "\n",
    "LIF 神经元模拟了神经元的兴奋和抑制过程。当输入电流 $I$ 足够大，使得膜电位 $V$ 超过阈值电位 $V_{\\mathrm{th}}$ 时，神经元会发放脉冲。在发放脉冲后，膜电位会被重置为 $V_{\\mathrm{reset}}$，并且在接下来的一段时间内，膜电位会逐渐恢复到静息电位 $V_{\\mathrm{rest}}$。\n",
    "\n",
    "![神经元脉冲发放过程](../_static/neuron-spike.gif)\n",
    "\n",
    "我们将上述方程转化为离散形式，得到：\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "V(t+1) =& V(t) + \\frac{\\Delta t}{\\tau_m} (-V(t) + V_{\\mathrm{rest}} + R I), \\\\\n",
    "Z(t) =& \\Theta(V(t) - V_{\\mathrm{th}}), \\\\\n",
    "V(t+1) =& (1 - Z(t)) * V(t+1) + Z(t) V_{\\mathrm{reset}}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1e5c44d7ea8294"
  },
  {
   "cell_type": "markdown",
   "source": [
    "**突触模型**\n",
    "\n",
    "最常见的突触模型是指数突触模型，其动力学方程如下：\n",
    "\n",
    "$$\n",
    "\\tau_s \\frac{ds}{dt} = -s + \\sum_i  W_i \\delta(t - t_i),\n",
    "$$\n",
    "\n",
    "其中，$s$ 是突触后电流，$\\tau_s$ 是突触后电流的时间常数，$t_i$ 是突触前神经元发放脉冲的时间。\n",
    "\n",
    "突触后电流 $s$ 是突触前神经元发放脉冲的叠加，而不是突触前神经元发放脉冲的数量。突触后电流 $s$ 会随着时间的推移而衰减，直到下一个突触前神经元发放脉冲。\n",
    "\n",
    "值得注意的是，指数突触模型可以很好地使用 AlignPost 方法来建模，正如[我们论文](https://doi.org/10.1101/2024.09.24.614728)中所提到的那样。在 AlignPost 方法中，突触后电流 $s$ 的维度与神经元的维度相同，每个维度对应所有汇聚到该神经元的突触电流。\n",
    "\n",
    "我们将上述方程转化为离散形式，得到：\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "s(t+1) =& \\alpha s(t) + W_1 Z_1(t) + \\cdots + W_n Z_n(t) \\\\\n",
    "I =& s(t)\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "其中，$\\alpha = \\exp(-\\Delta t / \\tau_s)$ 是突触后电流的衰减系数，$W_i$ 是第$i$个突触连接中的突触权重，$Z_i(t)$ 是突触前神经元群 $i$ 在时间 $t$ 的输出脉冲，$I$ 是上面LIF神经元接收到的总输入电流。\n",
    "\n",
    "\n",
    "另外，使用指数族突触模型来建模突触动力学中，经常使用的另一个模型是双指数突触模型。双指数突触模型在指数突触模型的基础上，增加了一个时间常数，用于描述突触后电流的上升和下降过程。指数突触和双指数突触模型的区别如下图所示：\n",
    "\n",
    "\n",
    "![Exponential-family synapse](../_static/expo-synapse.png)\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6324644f2da588d5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "**脉冲神经网络模型**\n",
    "\n",
    "基于上述的LIF神经元模型和指数突触模型，我们可以构建一个简单的脉冲神经网络模型。在这个模型中，我们假设神经元之间是全连接的，即每个神经元都与其他神经元相连。我们按照向量的形式，将整个网络的动力学方程表示如下：\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\mathbf{V}(t+1) =& \\mathbf{V}(t) + \\frac{\\Delta t}{\\tau_m} (-\\mathbf{V}(t) + V_{\\mathrm{rest}} + R \\mathbf{I}), \\\\\n",
    "\\mathbf{Z}(t) =& \\Theta(\\mathbf{V}(t) - V_{\\mathrm{th}}), \\\\\n",
    "\\mathbf{V}(t+1) =& (1 - \\mathbf{Z}(t)) \\odot \\mathbf{V}(t+1) + \\mathbf{Z}(t) \\odot V_{\\mathrm{reset}}, \\\\\n",
    "\\mathbf{s}(t+1) =& \\alpha \\mathbf{s}(t) + \\mathbf{W}^\\mathrm{in} \\mathbf{Z}^\\mathrm{in}(t) + \\mathbf{W}^\\mathrm{rec} \\mathbf{Z}(t), \\\\\n",
    "\\mathbf{I} =& \\mathbf{s}(t)\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "其中，$\\mathbf{V}$ 是神经元的膜电位向量，$\\mathbf{I}$ 是输入电流向量，$\\mathbf{Z}$ 是输出脉冲向量，$\\mathbf{s}$ 是突触后电流向量，$\\mathbf{W}^\\mathrm{in}$ 是输入突触权重矩阵，$\\mathbf{W}^\\mathrm{rec}$ 是网络内循环连接突触权重矩阵，$\\mathbf{Z}^\\mathrm{in}$ 是输入脉冲向量。\n",
    "\n",
    "上面我们只是简单地介绍了脉冲神经网络的基本概念，实际上，脉冲神经网络的动力学非常丰富。它可以包含非常多样性的神经元动力学、突触动力学、以及复杂的神经网络之间的拓扑结构。更多的内容可以参见[我们的论文](https://doi.org/10.1101/2024.09.24.614728)。在实际应用中，我们需要根据具体的任务需求，选择合适的神经元模型和突触模型，设计合理的网络结构，以及调整网络参数，来实现我们的目标。\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "965b26dff6e27ef0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. LIF神经网络模型\n",
    "\n",
    "我们\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9d72451e06e52571"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "72d8c14bb45947a6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. 广义积分发放神经网络\n",
    "\n",
    "接下来，让我们实现一个广义积分发放（Generalized Integrate-and-Fire, GIF）神经元模型，并使用指数突触模型来构建一个简单的脉冲神经网络模型。\n",
    "\n",
    "广义积分发放（Generalized Integrate-and-Fire, GIF）对经典积分发放模型的扩展,它可以更准确地描述真实神经元的动力学特性。与简单的积分发放模型相比,GIF模型考虑了动态阈值机制、适应性电流、后超极化效应、非线性膜响应等因素,从而更好地模拟神经元的动态行为。GIF模型的核心方程如下：\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "      &\\frac{d I_j}{d t} = - k_j I_j \\\\\n",
    "      &\\tau \\frac{d V}{d t} = - (V - V_\\mathrm{rest}) + R\\sum_{j}I_j + RI  \\\\\n",
    "      &\\frac{d V_{th}}{d t} = a(V - V_\\mathrm{rest}) - b(V_{th} - V_{th\\infty})\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "当$V>V_{th}$时，广义LIF神经元会触发：\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "&I_j \\leftarrow R_j I_j + A_j \\\\\n",
    "&V \\leftarrow V_\\mathrm{reset} \\\\\n",
    "&V_{th} \\leftarrow max(V_{th,\\mathrm{reset}}, V_\\mathrm{th})\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "\n",
    "其中，$V$ 是膜电位，$V_{rest}$ 是静息电位，$R$ 是膜电阻，$I$ 是输入电流，$V_{th}$ 是阈值电位，$V_{th\\infty}$ 是静息阈值电位，$a$ 和 $b$ 是阈值动力学参数，$I_j$ 是适应性电流，表示任意数量的内部电流，$R_j$ 是适应性电流的衰减系数，$A_j$ 是适应性电流的增量，$V_\\mathrm{reset}$ 是重置电位，$V_{th, \\mathrm{reset}}$ 是阈值重置电位。\n",
    "\n",
    "\n",
    "GIF模型通过引入多个参数和机制，能够模拟不同类型的神经元行为，例如：\n",
    "- **适应性**：可以通过引入适应性电流，模拟神经元在重复刺激下的放电模式。\n",
    "- **后发放抑制**：通过设置抑制机制来模拟发放后的短暂恢复期。\n",
    "- **多种放电模式**：通过调整参数，模型可以重现各种生物神经元的放电特性，如快速发放、适应性发放和脉冲发放。\n",
    "\n",
    "在这里，我们使用一个简化的GIF模型，实现一个简单的脉冲神经网络模型。简化的GIF模型只包含了适应性电流机制，不包含后发放抑制和多种放电模式。其动力学方程如下：\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "&\\tau_{\\mathbf{a}}\\frac{\\mathrm{d}\\mathbf{a}}{\\mathrm{d}t}=-\\mathbf{a},\\\\&\\tau\\frac{d\\mathbf{v}}{dt}=-\\mathbf{v}+V_{\\mathrm{rest}}+\\mathbf{a}+\\mathbf{I},\\end{aligned}\n",
    "$$\n",
    "\n",
    "其中$\\mathbf{a}$表示内部自适应电流，$\\tau_\\mathbf{a}$是自适应电流的时间常数。当第$i$个神经元的$v_i$满足$V_\\mathrm{th}$时，模型触发：\n",
    "\n",
    "$$\n",
    "\\mathbf{a}_{i}\\leftarrow\\mathbf{a}_{i}+A,\\\\\n",
    "\\mathbf{v}_{i}\\leftarrow V_{\\mathrm{reset}},\n",
    "$$\n",
    "\n",
    "\n",
    "我们将上述方程转化为离散形式，得到：\n",
    "\n",
    "$$\n",
    "\\begin{aligned}&\\bar{\\mathbf{v}}^{t-1}=\\mathbf{v}^{t-1}+\\mathbf{z}^{t-1}(V_{\\mathrm{reset}}-\\mathbf{v}^{t-1}),\\\\&\\mathbf{a}^{t}=e^{-\\Delta t/\\tau_{\\mathbf{a}}}\\mathbf{a}^{t-1}+\\mathbf{z}^{t-1}A,\\\\&\\mathbf{v}^{t}=e^{-\\Delta t/\\tau}\\bar{\\mathbf{v}}^{t-1}+(1-e^{-\\Delta t/\\tau})(V_{\\mathrm{rest}}+\\mathbf{I}^{t}+\\mathbf{a}^{t}).\\end{aligned}\n",
    "$$\n",
    "\n",
    "以下是这个GIF神经元模型的实现："
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f5a77c680c42e6cd"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from typing import Callable\n",
    "\n",
    "\n",
    "class GIF(bst.nn.Neuron):\n",
    "    def __init__(\n",
    "        self, size,\n",
    "        V_rest=0. * u.mV,\n",
    "        V_th_inf=1. * u.mV,\n",
    "        R=1. * u.ohm,\n",
    "        tau=20. * u.ms,\n",
    "        tau_I2=50. * u.ms,\n",
    "        A2=0. * u.mA,\n",
    "        V_initializer: Callable = bst.init.ZeroInit(unit=u.mV),\n",
    "        I2_initializer: Callable = bst.init.ZeroInit(unit=u.mA),\n",
    "        spike_fun: Callable = bst.surrogate.ReluGrad(),\n",
    "        spk_reset: str = 'soft',\n",
    "        keep_size: bool = False,\n",
    "        name: str = None,\n",
    "    ):\n",
    "        super().__init__(size, keep_size=keep_size, name=name, spk_fun=spike_fun, spk_reset=spk_reset)\n",
    "\n",
    "        # parameters\n",
    "        self.V_rest = bst.init.param(V_rest, self.varshape, allow_none=False)\n",
    "        self.V_th_inf = bst.init.param(V_th_inf, self.varshape, allow_none=False)\n",
    "        self.R = bst.init.param(R, self.varshape, allow_none=False)\n",
    "        self.tau = bst.init.param(tau, self.varshape, allow_none=False)\n",
    "        self.tau_I2 = bst.init.param(tau_I2, self.varshape, allow_none=False)\n",
    "        self.A2 = bst.init.param(A2, self.varshape, allow_none=False)\n",
    "\n",
    "        # initializers\n",
    "        self._V_initializer = V_initializer\n",
    "        self._I2_initializer = I2_initializer\n",
    "\n",
    "    def init_state(self, batch_size=None):\n",
    "        # 将模型用于在线学习，需要初始化状态变量\n",
    "        self.V = brainscale.ETraceState(bst.init.param(self._V_initializer, self.varshape, batch_size))\n",
    "        self.I2 = brainscale.ETraceState(bst.init.param(self._I2_initializer, self.varshape, batch_size))\n",
    "\n",
    "    def update(self, x=0.):\n",
    "        # 如果前一时刻发放了脉冲，则将膜电位和适应性电流进行重置\n",
    "        last_spk = self.get_spike()\n",
    "        last_spk = jax.lax.stop_gradient(last_spk)\n",
    "        last_V = self.V.value - self.V_th_inf * last_spk\n",
    "        last_I2 = self.I2.value - self.A2 * last_spk\n",
    "        # 更新状态\n",
    "        I2 = bst.nn.exp_euler_step(lambda i2: - i2 / self.tau_I2, last_I2)\n",
    "        V = bst.nn.exp_euler_step(lambda v, Iext: (- v + self.V_rest + self.R * Iext) / self.tau,\n",
    "                                  last_V, x + I2)\n",
    "        self.I2.value = I2\n",
    "        self.V.value = V\n",
    "        # 输出\n",
    "        inp = self.V.value - self.V_th_inf\n",
    "        inp = jax.nn.standardize(u.get_magnitude(inp))\n",
    "        return inp\n",
    "\n",
    "    def get_spike(self, V=None):\n",
    "        V = self.V.value if V is None else V\n",
    "        spk = self.spk_fun((V - self.V_th_inf) / self.V_th_inf)\n",
    "        return spk"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f9f41df6b1b66508"
  },
  {
   "cell_type": "markdown",
   "source": [
    "在上面的代码中，我们定义了一个GIF神经元模型，其中包含了适应性电流机制。我们使用指数欧拉方法来更新神经元的状态，其中包括膜电位和适应性电流。在每个时间步，我们计算膜电位和适应性电流的变化，并根据阈值电位是否超过阈值来判断是否发放脉冲。如果发放脉冲，则将膜电位和适应性电流进行重置。\n",
    "\n",
    "接下来，我们将使用这个GIF神经元模型+指数突触模型来构建一个三层的脉冲神经网络模型，第一层是输入层，第二层是隐藏层，第三层是输出层。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "228e4f11cb9aa44e"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class GifNet(bst.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_in: int,\n",
    "        n_rec: int,\n",
    "        n_out: int,\n",
    "        ff_scale: float = 1.,\n",
    "        rec_scale: float = 1.,\n",
    "        tau_neu: float = 5. * u.ms,\n",
    "        tau_syn: float = 5. * u.ms,\n",
    "        tau_I2: float = 5. * u.ms,\n",
    "        A2=-1. * u.mA,\n",
    "        tau_o: float = 5. * u.ms,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        # 初始化权重\n",
    "        ff_init = bst.init.KaimingNormal(ff_scale, unit=u.mA)\n",
    "        rec_init = bst.init.KaimingNormal(rec_scale, unit=u.mA)\n",
    "        w = u.math.concatenate([ff_init((n_in, n_rec)), rec_init((n_rec, n_rec))], axis=0)\n",
    "\n",
    "        # 参数\n",
    "        self.n_in = n_in\n",
    "        self.n_rec = n_rec\n",
    "        self.n_out = n_out\n",
    "\n",
    "        # 模型层\n",
    "        self.ir2r = brainscale.nn.Linear(n_in + n_rec, n_rec, w_init=w, b_init=bst.init.ZeroInit(unit=u.mA))\n",
    "        self.exp = brainscale.nn.Expon(n_rec, tau=tau_syn, g_initializer=bst.init.ZeroInit(unit=u.mA))\n",
    "        self.r = GIF(\n",
    "            n_rec,\n",
    "            V_rest=0. * u.mV,\n",
    "            V_th_inf=1. * u.mV,\n",
    "            A2=A2,\n",
    "            tau=tau_neu,\n",
    "            tau_I2=bst.random.uniform(100., tau_I2 * 1.5, n_rec) * u.ms,\n",
    "        )\n",
    "        self.out = brainscale.nn.LeakyRateReadout(n_rec, n_out, tau=tau_o, w_init=bst.init.KaimingNormal())\n",
    "\n",
    "    def update(self, spikes):\n",
    "        cond = self.ir2r(u.math.concatenate([spikes, self.r.get_spike()], axis=-1))\n",
    "        out = self.r(self.exp(cond))\n",
    "        return self.out(out)\n",
    "\n",
    "    def verify(self, input_spikes, num_show=5, sps_inc=10.):\n",
    "        def _step(x):\n",
    "            out = self.update(x)\n",
    "            return out, self.r.get_spike(), self.r.V.value\n",
    "\n",
    "        # 输入脉冲\n",
    "        xs = np.transpose(input_spikes, (1, 0, 2))  # [n_steps, n_samples, n_in]\n",
    "\n",
    "        # 运行仿真模型\n",
    "        bst.nn.init_all_states(self, xs.shape[1])\n",
    "        outs, sps, vs = bst.compile.for_loop(_step, xs)\n",
    "        outs = u.math.as_numpy(outs)\n",
    "        sps = u.math.as_numpy(sps)\n",
    "        vs = u.math.as_numpy(vs)\n",
    "        vs = np.where(sps, vs + sps_inc, vs)\n",
    "        max_t = xs.shape[0]\n",
    "\n",
    "        for i in range(num_show):\n",
    "            fig, gs = bts.visualize.get_figure(4, 1, 2., 10.)\n",
    "\n",
    "            # 输入活动可视化\n",
    "            ax_inp = fig.add_subplot(gs[0, 0])\n",
    "            t_indices, n_indices = np.where(xs[:, i] > 0)\n",
    "            ax_inp.plot(t_indices, n_indices, '.')\n",
    "            ax_inp.set_xlim(0., max_t)\n",
    "            ax_inp.set_ylabel('Input Activity')\n",
    "\n",
    "            # 神经元活动可视化\n",
    "            ax = fig.add_subplot(gs[1, 0])\n",
    "            plt.plot(vs[:, i])\n",
    "            ax.set_xlim(0., max_t)\n",
    "            ax.set_ylabel('Recurrent Potential')\n",
    "\n",
    "            # 脉冲活动可视化\n",
    "            ax_rec = fig.add_subplot(gs[2, 0])\n",
    "            t_indices, n_indices = np.where(sps[:, i] > 0)\n",
    "            ax_rec.plot(t_indices, n_indices, '.')\n",
    "            ax_rec.set_xlim(0., max_t)\n",
    "            ax_rec.set_ylabel('Recurrent Spiking')\n",
    "\n",
    "            # 输出活动可视化\n",
    "            ax_out = fig.add_subplot(gs[3, 0])\n",
    "            for j in range(outs.shape[-1]):\n",
    "                ax_out.plot(outs[:, i, j], label=f'Readout {j}', alpha=0.7)\n",
    "            ax_out.set_ylabel('Output Activity')\n",
    "            ax_out.set_xlabel('Time [ms]')\n",
    "            ax_out.set_xlim(0., max_t)\n",
    "            plt.legend()\n",
    "\n",
    "        plt.show()\n",
    "        plt.close()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9386ef8ad36c22df"
  },
  {
   "cell_type": "markdown",
   "source": [
    "在上面的代码中，我们定义了一个三层的脉冲神经网络模型，其中包含了一个输入层、一个隐藏层和一个输出层。隐藏层使用了我们上面定义的GIF神经元模型，包含了适应性电流机制。在每个时间步，我们计算输入层和隐藏层的脉冲输出，并根据隐藏层的脉冲输出来更新隐藏层的状态。最后，我们使用隐藏层的状态来计算输出层的输出。特别地，我们定义了一个`verify`方法，用于可视化网络的活动。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6e4e1bfbedcf8eab"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. 延迟样本匹配任务\n",
    "\n",
    "我们准备使用上面定义的脉冲神经网络模型来解决一个简单的延迟样本匹配任务。\n",
    "\n",
    "延迟样本匹配任务（Delayed Matching-to-Sample, DMS）是一种经典的工作记忆任务，用于研究动物的工作记忆能力。在这个任务中，动物需要记住一个延迟时间内的样本，然后在延迟时间结束后，从多个选项中选择与样本相匹配的选项。这个任务可以用来研究动物的工作记忆能力，以及相关的神经机制。\n",
    "\n",
    "在这里，我们首先构建一个延迟样本匹配任务的数据集。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6663e425826ab2a1"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import numba\n",
    "\n",
    "\n",
    "@numba.njit\n",
    "def _dms(num_steps, num_inputs, n_motion_choice, motion_tuning,\n",
    "         sample_time, test_time, fr, bg_fr, rotate_dir):\n",
    "    # data\n",
    "    X = np.zeros((num_steps, num_inputs))\n",
    "\n",
    "    # sample\n",
    "    match = np.random.randint(2)\n",
    "    sample_dir = np.random.randint(n_motion_choice)\n",
    "\n",
    "    # Generate the sample and test stimuli based on the rule\n",
    "    if match == 1:  # match trial\n",
    "        test_dir = (sample_dir + rotate_dir) % n_motion_choice\n",
    "    else:\n",
    "        test_dir = np.random.randint(n_motion_choice)\n",
    "        while test_dir == ((sample_dir + rotate_dir) % n_motion_choice):\n",
    "            test_dir = np.random.randint(n_motion_choice)\n",
    "\n",
    "    # SAMPLE stimulus\n",
    "    X[sample_time] += motion_tuning[sample_dir] * fr\n",
    "    # TEST stimulus\n",
    "    X[test_time] += motion_tuning[test_dir] * fr\n",
    "    X += bg_fr\n",
    "\n",
    "    # to spiking\n",
    "    X = np.random.random(X.shape) < X\n",
    "    X = X.astype(np.float32)\n",
    "\n",
    "    # can use a greater weight for test period if needed\n",
    "    return X, match\n",
    "\n",
    "\n",
    "class DMSDataset:\n",
    "    \"\"\"\n",
    "    Delayed match-to-sample task.\n",
    "    \"\"\"\n",
    "    times = ('dead', 'fixation', 'sample', 'delay', 'test')\n",
    "    output_features = ('non-match', 'match')\n",
    "\n",
    "    _rotate_choice = {\n",
    "        '0': 0,\n",
    "        '45': 1,\n",
    "        '90': 2,\n",
    "        '135': 3,\n",
    "        '180': 4,\n",
    "        '225': 5,\n",
    "        '270': 6,\n",
    "        '315': 7,\n",
    "        '360': 8,\n",
    "    }\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        t_fixation=500. * u.ms,\n",
    "        t_sample=500. * u.ms,\n",
    "        t_delay=1000. * u.ms,\n",
    "        t_test=500. * u.ms,\n",
    "        limits=(0., np.pi * 2),\n",
    "        rotation_match='0',\n",
    "        kappa=3.,\n",
    "        bg_fr=1. * u.Hz,\n",
    "        n_input=100,\n",
    "        firing_rate=100. * u.Hz,\n",
    "        batch_size: int = 128,\n",
    "        num_batch: int = 1000,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        # parameters\n",
    "        self.num_batch = num_batch\n",
    "        self.batch_size = batch_size\n",
    "        self.num_inputs = n_input\n",
    "        self.num_outputs = 2\n",
    "        self.firing_rate = firing_rate\n",
    "        dt = bst.environ.get_dt()\n",
    "\n",
    "        # time\n",
    "        self.t_fixation = int(t_fixation / dt)\n",
    "        self.t_sample = int(t_sample / dt)\n",
    "        self.t_delay = int(t_delay / dt)\n",
    "        self.t_test = int(t_test / dt)\n",
    "        self.num_steps = self.t_fixation + self.t_sample + self.t_delay + self.t_test\n",
    "        test_onset = self.t_fixation + self.t_sample + self.t_delay\n",
    "        self._test_onset = test_onset\n",
    "        self.test_time = slice(test_onset, test_onset + self.t_test)\n",
    "        self.fix_time = slice(0, test_onset)\n",
    "        self.sample_time = slice(self.t_fixation, self.t_fixation + self.t_sample)\n",
    "\n",
    "        # input shape\n",
    "        self.rotation_match = rotation_match\n",
    "        self._rotate = self._rotate_choice[rotation_match]\n",
    "        self.bg_fr = bg_fr  # background firing rate\n",
    "        self.v_min = limits[0]\n",
    "        self.v_max = limits[1]\n",
    "        self.v_range = limits[1] - limits[0]\n",
    "\n",
    "        # Tuning function data\n",
    "        self.n_motion_choice = 8\n",
    "        self.kappa = kappa  # concentration scaling factor for von Mises\n",
    "\n",
    "        # Generate list of preferred directions\n",
    "        # dividing neurons by 2 since two equal\n",
    "        # groups representing two modalities\n",
    "        pref_dirs = np.arange(self.v_min, self.v_max, self.v_range / self.num_inputs)\n",
    "\n",
    "        # Generate list of possible stimulus directions\n",
    "        stim_dirs = np.arange(self.v_min, self.v_max, self.v_range / self.n_motion_choice)\n",
    "\n",
    "        d = np.cos(np.expand_dims(stim_dirs, 1) - pref_dirs)\n",
    "        self.motion_tuning = np.exp(self.kappa * d) / np.exp(self.kappa)\n",
    "\n",
    "    @property\n",
    "    def n_sim(self):\n",
    "        return self._test_onset\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_batch\n",
    "\n",
    "    def __iter__(self):\n",
    "        # firing rate\n",
    "        fr = np.asarray(self.firing_rate * bst.environ.get_dt())\n",
    "        bg_fr = np.asarray(self.bg_fr * bst.environ.get_dt())\n",
    "\n",
    "        # generate data\n",
    "        for _ in range(self.num_batch):\n",
    "            xs, ys = [], []\n",
    "            for _ in range(self.batch_size):\n",
    "                x, y = _dms(self.num_steps,\n",
    "                            self.num_inputs,\n",
    "                            self.n_motion_choice,\n",
    "                            self.motion_tuning,\n",
    "                            self.sample_time,\n",
    "                            self.test_time,\n",
    "                            fr,\n",
    "                            bg_fr,\n",
    "                            self._rotate)\n",
    "                xs.append(x)\n",
    "                ys.append(y)\n",
    "            yield np.asarray(xs), np.asarray(ys)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "61efe4b54d88e152"
  },
  {
   "cell_type": "markdown",
   "source": [
    "在上面的代码中，我们定义了一个延迟样本匹配任务的数据集，其中包含了样本时间、测试时间、延迟时间等参数。我们使用von Mises函数来生成样本和测试的方向，然后将其转化为脉冲活动。我们还定义了一个`DMSDataset`类，用于生成延迟样本匹配任务的数据集。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7bc129af70f5f1ef"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4. 训练器"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7b5ac4468afc9f15"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import braintools as bts\n",
    "from tqdm import tqdm\n",
    "from typing import Iterable, Union\n",
    "import jax\n",
    "\n",
    "LOSS = float\n",
    "ACCURACY = float\n",
    "\n",
    "\n",
    "\n",
    "class Trainer(object):\n",
    "    def __init__(\n",
    "        self,\n",
    "        target: GifNet,\n",
    "        opt: bst.optim.Optimizer,\n",
    "        dataset: Iterable,\n",
    "        n_sim: int = 0,\n",
    "        batch_size: int = 128,\n",
    "        max_acc: float = 0.90,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        # dataset\n",
    "        self.dataset = dataset\n",
    "\n",
    "        # target network\n",
    "        self.target = target\n",
    "\n",
    "        # optimizer\n",
    "        self.opt = opt\n",
    "        weights = self.target.states().subset(bst.ParamState)\n",
    "        opt.register_trainable_weights(weights)\n",
    "\n",
    "        # training parameters\n",
    "        self.n_sim = n_sim\n",
    "        self.batch_size = batch_size\n",
    "        self.max_acc = max_acc\n",
    "\n",
    "    def _acc(self, out, target):\n",
    "        return jax.numpy.mean(jax.numpy.equal(target, jax.numpy.argmax(jax.numpy.mean(out, axis=0), axis=1)))\n",
    "\n",
    "    def batch_train(self, xs, ys) -> Union[LOSS, ACCURACY]:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def f_train(self):\n",
    "        losses, accs = [], []\n",
    "        n_batch = len(self.dataset)\n",
    "        i_epoch = 0\n",
    "        acc_ = 0.\n",
    "        while acc_ < self.max_acc:\n",
    "            i_epoch += 1\n",
    "            bar = tqdm(enumerate(self.dataset))\n",
    "            for i, (x_local, y_local) in bar:\n",
    "                # training\n",
    "                x_local = np.transpose(x_local, (1, 0, 2))  # [n_steps, n_samples, n_in]\n",
    "                y_local = y_local  # [n_samples]\n",
    "                loss, acc = self.batch_train(x_local, y_local)\n",
    "                bar.set_description(f'loss = {loss:.5f}, acc={acc:.5f}', refresh=True)\n",
    "                losses.append(loss)\n",
    "                accs.append(acc)\n",
    "            acc_ = np.mean(accs[-n_batch:])\n",
    "            print(f'Epoch {i_epoch}, acc={acc_:.5f}, loss={np.mean(losses[-n_batch:]):.5f}')\n",
    "        return np.asarray(losses), np.asarray(accs)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c6cf630b5fdb711d"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class OnlineTrainer(Trainer):\n",
    "    @bst.compile.jit(static_argnums=(0,))\n",
    "    def batch_train(self, inputs, targets):\n",
    "        # initialize the states\n",
    "        bst.nn.init_all_states(self.target, inputs.shape[1])\n",
    "\n",
    "        # weights\n",
    "        weights = self.target.states().subset(bst.ParamState)\n",
    "\n",
    "        # initialize the online learning model\n",
    "        model = brainscale.DiagIODimAlgorithm(self.target, decay_or_rank=0.99)\n",
    "        model.compile_graph(inputs[0])\n",
    "\n",
    "        def _etrace_grad(i, inp):\n",
    "            # call the model\n",
    "            out = model(inp, running_index=i)\n",
    "            # calculate the loss\n",
    "            loss = bts.metric.softmax_cross_entropy_with_integer_labels(out, targets).mean()\n",
    "            return loss, out\n",
    "\n",
    "        def _etrace_step(prev_grads, x):\n",
    "            # no need to return weights and states, since they are generated then no longer needed\n",
    "            i, inp = x\n",
    "            f_grad = bst.augment.grad(_etrace_grad, weights, has_aux=True, return_value=True)\n",
    "            cur_grads, local_loss, out = f_grad(i, inp)\n",
    "            next_grads = jax.tree.map(lambda a, b: a + b, prev_grads, cur_grads)\n",
    "            return next_grads, (out, local_loss)\n",
    "\n",
    "        def _etrace_train(indices_, inputs_):\n",
    "            # forward propagation\n",
    "            grads = jax.tree.map(u.math.zeros_like, weights.to_dict_values())\n",
    "            grads, (outs, losses) = bst.compile.scan(_etrace_step, grads, (indices_, inputs_))\n",
    "            # gradient updates\n",
    "            grads = bst.functional.clip_grad_norm(grads, 1.)\n",
    "            self.opt.update(grads)\n",
    "            # accuracy\n",
    "            return losses.mean(), outs\n",
    "\n",
    "        # running indices\n",
    "        indices = np.arange(inputs.shape[0])\n",
    "        if self.n_sim > 0:\n",
    "            bst.compile.for_loop(lambda i, inp: model(inp, running_index=i), indices[:self.n_sim], inputs[:self.n_sim])\n",
    "        loss, outs = _etrace_train(indices[self.n_sim:], inputs[self.n_sim:])\n",
    "\n",
    "        # returns\n",
    "        return loss, self._acc(outs, targets)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "492fd7fadf1d31b1"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class BPTTTrainer(Trainer):\n",
    "    @bst.compile.jit(static_argnums=(0,))\n",
    "    def bptt_train(self, inputs, targets):\n",
    "        # initialize the states\n",
    "        bst.nn.init_all_states(self.target, inputs.shape[1])\n",
    "\n",
    "        # the model for a single step\n",
    "        def _run_step_train(inp):\n",
    "            out = self.target(inp)\n",
    "            loss = bts.metric.softmax_cross_entropy_with_integer_labels(out, targets).mean()\n",
    "            return out, loss\n",
    "\n",
    "        def _bptt_grad_step():\n",
    "            if self.n_sim > 0:\n",
    "                _ = bst.compile.for_loop(self.target, inputs[:self.n_sim])\n",
    "            outs, losses = bst.compile.for_loop(_run_step_train, inputs[self.n_sim:])\n",
    "            return losses.mean(), outs\n",
    "\n",
    "        # gradients\n",
    "        weights = self.target.states().subset(bst.ParamState)\n",
    "        grads, loss, outs = bst.augment.grad(_bptt_grad_step, weights, has_aux=True, return_value=True)()\n",
    "\n",
    "        # optimization\n",
    "        grads = bst.functional.clip_grad_norm(grads, 1.)\n",
    "        self.opt.update(grads)\n",
    "\n",
    "        return loss, self._acc(outs, targets)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6b1bcf3795f42946"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5. 使用GIF SNN进行DMS任务的在线学习"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "de55bff9849ee7dc"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "with bst.environ.context(dt=1. * u.ms):\n",
    "    data = DMSDataset(\n",
    "        bg_fr=1. * u.Hz,\n",
    "        t_fixation=100. * u.ms,\n",
    "        t_sample=200. * u.ms,\n",
    "        t_delay=500. * u.ms,\n",
    "        t_test=200. * u.ms,\n",
    "        n_input=100,\n",
    "        firing_rate=100. * u.Hz,\n",
    "        batch_size=128,\n",
    "        num_batch=100,\n",
    "    )\n",
    "    net = GifNet(\n",
    "        n_in=100,\n",
    "        n_rec=200,\n",
    "        n_out=2,\n",
    "        tau_neu=100. * u.ms,\n",
    "        tau_syn=100. * u.ms,\n",
    "        tau_I2=500. * u.ms,\n",
    "        A2=1. * u.mA,\n",
    "    )\n",
    "    net.verify(next(iter(data))[0], num_show=2)\n",
    "\n",
    "    onliner = OnlineTrainer(\n",
    "        target=net,\n",
    "        opt=bst.optim.Adam(lr=1e-3),\n",
    "        dataset=data,\n",
    "        n_sim=data.n_sim,\n",
    "    )\n",
    "\n",
    "    losses, accs = onliner.f_train()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d82cd0fa45e206cb"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "fig, gs = bts.visualize.get_figure(1, 2, 4., 5.)\n",
    "fig.add_subplot(gs[0, 0])\n",
    "plt.plot(losses)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "fig.add_subplot(gs[0, 1])\n",
    "plt.plot(accs)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dc0dc26410868807"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "ca16a6d8876d2b11"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "da94c1e8da1ffa69"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 6. 使用LIF SNN进行Meromorphic-MNIST的在线学习"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7b78ceff439dd8b1"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import tonic\n",
    "from tonic.datasets import NMNIST\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "def numpy_collate(batch):\n",
    "    if isinstance(batch[0], np.ndarray):\n",
    "        return np.stack(batch)\n",
    "    elif isinstance(batch[0], (tuple, list)):\n",
    "        transposed = zip(*batch)\n",
    "        return [numpy_collate(samples) for samples in transposed]\n",
    "    else:\n",
    "        return np.array(batch)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e22f971cf101f55a"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "27fbe8360e8ceed2"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "db010b44a7c47232"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 7. 总结"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6b85483e325a2e21"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "61fc080f27505691"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
